<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>PHP 快速读取大文件 | 博客</title>

  
  <meta name="author" content="403 Forbidden">
  

  
  <meta name="description" content="最近想分析一下iis的日志，由于日志文件800M等大文件，所以怎样使用PHP快速读取成了问题！首先排除了file，因为加载太慢,内存溢出！后来考虑用指针fgets，但是读取还是有点慢，如果只读取1000条以内的数据还是可以接受的最后试用了PHP的stream_get_line函数 ，读取快速，读取5">
  

  
  
  <meta name="keywords" content="">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="PHP 快速读取大文件"/>

  <meta property="og:site_name" content="博客"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="博客" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">博客</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/categories">分类</a></li>
      
        <li><a href="/about.html">关于</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>PHP 快速读取大文件</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2014/12/16/PHP 快速读取大文件/" rel="bookmark">
        <time class="entry-date published" datetime="2014-12-16T05:57:14.000Z">
          2014-12-16
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>最近想分析一下iis的日志，由于日志文件800M等大文件，所以怎样使用PHP快速读取成了问题！首先排除了file，因为加载太慢,内存溢出！<br>后来考虑用指针fgets，但是读取还是有点慢，如果只读取1000条以内的数据还是可以接受的<br>最后试用了PHP的stream_get_line函数 ，读取快速，读取50万条数据大文件，大概需要20秒左右的时间！例子代码如下</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$fp = fopen(<span class="string">'./iis.log'</span>, <span class="string">'r'</span>); <span class="comment">//文件</span></span><br><span class="line"><span class="keyword">while</span> (!feof($fp)) &#123;</span><br><span class="line">	<span class="comment">//for($j=1;$j&lt;=1000;$j++) &#123;		 //读取下面的1000行并存储到数组中</span></span><br><span class="line">	 $logarray[] = stream_get_line($fp, <span class="number">65535</span>, <span class="string">"\n"</span>);</span><br><span class="line">		<span class="comment">// break;</span></span><br><span class="line">	 <span class="comment">// &#125;</span></span><br><span class="line"> </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>转载自 <a href="http://www.wenlingnet.com/index.php/172/" target="_blank" rel="noopener">http://www.wenlingnet.com/index.php/172/</a></p>
<p>P.S. 说实话这个是挺快的，就是没法指定起始位置<br><a href="/uploads/2014/12/QQ图片20141216215656.png"><img src="/uploads/2014/12/QQ图片20141216215656-1024x551.png" alt="QQ图片20141216215656"></a></p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/Web-开发/">Web 开发</a>
    </span>
    

    

    </div>

    
  </div>
</article>

  

	<section id="comment" class="comment">
	  <div id="disqus_thread">
	  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	  </div>
	</section>

	<script type="text/javascript">
	var disqus_shortname = 'futa-ooo';
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	</script>




    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2019 403 Forbidden
    
  </p>
</footer>
    
  </div>
</div>
</body>
</html>